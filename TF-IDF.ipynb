{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef1e7980",
   "metadata": {},
   "source": [
    "# Term Frequency and Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92a89dd",
   "metadata": {},
   "source": [
    "This method is used to convert words to vectors. Bag of words was also used for the same purpose, but the problem with bag of words was that, it only converted the words in either 0 or the frequency of that word. Their was no weightage given to the words. So if we want to carry out task like symentic analysis, then this method will not help us. So to overcome this problem TF-IDF is used. Here in this method more importance is given to the words which are important and plays a vital role in giving meaning to the sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2debc29c",
   "metadata": {},
   "source": [
    "### How does this method work ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24daab8",
   "metadata": {},
   "source": [
    "As usual,first we will perform the text cleaning tasks, like removing the stop words and performing either Lemmatization or Stemming. After we get the text corpus, now next step is to caclculate the Term Frequency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500b068e",
   "metadata": {},
   "source": [
    "Term Frequency (TF) = (No. of repeation of words in a sentence) / (No. of words in a sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c602cb87",
   "metadata": {},
   "source": [
    "Inverse Document Frequency (IDF) = log(No. of sentences / No. of sentences containing the word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22348d8a",
   "metadata": {},
   "source": [
    "And finally TF-IDF = TF * IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "481967c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "para = '''\n",
    "Mr. Aakash Patel is 23 years old. The date is 3rd Feburary 2022. Time is 1PM.\n",
    "By impossible of in difficulty discovered celebrated ye. Justice joy manners boy met resolve produce. Bed head loud next plan rent had easy add him. As earnestly shameless elsewhere defective estimable fulfilled of. Esteem my advice it an excuse enable. Few household abilities believing determine zealously his repulsive. To open draw dear be by side like.\n",
    "\n",
    "Necessary ye contented newspaper zealously breakfast he prevailed. Melancholy middletons yet understood decisively boy law she. Answer him easily are its barton little. Oh no though mother be things simple itself. Dashwood horrible he strictly on as. Home fine in so am good body this hope.\n",
    "\n",
    "Knowledge nay estimable questions repulsive daughters boy. Solicitude gay way unaffected expression for. His mistress ladyship required off horrible disposed rejoiced. Unpleasing pianoforte unreserved as oh he unpleasant no inquietude insipidity. Advantages can discretion possession add favourable cultivated admiration far. Why rather assure how esteem end hunted nearer and before. By an truth after heard going early given he. Charmed to it excited females whether at examine. Him abilities suffering may are yet dependent.\n",
    "\n",
    "Do am he horrible distance marriage so although. Afraid assure square so happen mr an before. His many same been well can high that. Forfeited did law eagerness allowance improving assurance bed. Had saw put seven joy short first. Pronounce so enjoyment my resembled in forfeited sportsman. Which vexed did began son abode short may. Interested astonished he at cultivated or me. Nor brought one invited she produce her.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c10cbf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d33077c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet = WordNetLemmatizer()\n",
    "sentences = nltk.sent_tokenize(para)\n",
    "corpus = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c2ac6979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nMr. Aakash Patel is 23 years old.',\n",
       " 'The date is 3rd Feburary 2022.',\n",
       " 'Time is 1PM.',\n",
       " 'By impossible of in difficulty discovered celebrated ye.',\n",
       " 'Justice joy manners boy met resolve produce.',\n",
       " 'Bed head loud next plan rent had easy add him.',\n",
       " 'As earnestly shameless elsewhere defective estimable fulfilled of.',\n",
       " 'Esteem my advice it an excuse enable.',\n",
       " 'Few household abilities believing determine zealously his repulsive.',\n",
       " 'To open draw dear be by side like.',\n",
       " 'Necessary ye contented newspaper zealously breakfast he prevailed.',\n",
       " 'Melancholy middletons yet understood decisively boy law she.',\n",
       " 'Answer him easily are its barton little.',\n",
       " 'Oh no though mother be things simple itself.',\n",
       " 'Dashwood horrible he strictly on as.',\n",
       " 'Home fine in so am good body this hope.',\n",
       " 'Knowledge nay estimable questions repulsive daughters boy.',\n",
       " 'Solicitude gay way unaffected expression for.',\n",
       " 'His mistress ladyship required off horrible disposed rejoiced.',\n",
       " 'Unpleasing pianoforte unreserved as oh he unpleasant no inquietude insipidity.',\n",
       " 'Advantages can discretion possession add favourable cultivated admiration far.',\n",
       " 'Why rather assure how esteem end hunted nearer and before.',\n",
       " 'By an truth after heard going early given he.',\n",
       " 'Charmed to it excited females whether at examine.',\n",
       " 'Him abilities suffering may are yet dependent.',\n",
       " 'Do am he horrible distance marriage so although.',\n",
       " 'Afraid assure square so happen mr an before.',\n",
       " 'His many same been well can high that.',\n",
       " 'Forfeited did law eagerness allowance improving assurance bed.',\n",
       " 'Had saw put seven joy short first.',\n",
       " 'Pronounce so enjoyment my resembled in forfeited sportsman.',\n",
       " 'Which vexed did began son abode short may.',\n",
       " 'Interested astonished he at cultivated or me.',\n",
       " 'Nor brought one invited she produce her.']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e8023f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sentences)):\n",
    "    review = re.sub('[^a-zA-Z0-9]' , ' ' , sentences[i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [wordnet.lemmatize(word) for word in review if word not in set(stopwords.words(\"english\"))]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ce121a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mr aakash patel 23 year old',\n",
       " 'date 3rd feburary 2022',\n",
       " 'time 1pm',\n",
       " 'impossible difficulty discovered celebrated ye',\n",
       " 'justice joy manner boy met resolve produce',\n",
       " 'bed head loud next plan rent easy add',\n",
       " 'earnestly shameless elsewhere defective estimable fulfilled',\n",
       " 'esteem advice excuse enable',\n",
       " 'household ability believing determine zealously repulsive',\n",
       " 'open draw dear side like',\n",
       " 'necessary ye contented newspaper zealously breakfast prevailed',\n",
       " 'melancholy middleton yet understood decisively boy law',\n",
       " 'answer easily barton little',\n",
       " 'oh though mother thing simple',\n",
       " 'dashwood horrible strictly',\n",
       " 'home fine good body hope',\n",
       " 'knowledge nay estimable question repulsive daughter boy',\n",
       " 'solicitude gay way unaffected expression',\n",
       " 'mistress ladyship required horrible disposed rejoiced',\n",
       " 'unpleasing pianoforte unreserved oh unpleasant inquietude insipidity',\n",
       " 'advantage discretion possession add favourable cultivated admiration far',\n",
       " 'rather assure esteem end hunted nearer',\n",
       " 'truth heard going early given',\n",
       " 'charmed excited female whether examine',\n",
       " 'ability suffering may yet dependent',\n",
       " 'horrible distance marriage although',\n",
       " 'afraid assure square happen mr',\n",
       " 'many well high',\n",
       " 'forfeited law eagerness allowance improving assurance bed',\n",
       " 'saw put seven joy short first',\n",
       " 'pronounce enjoyment resembled forfeited sportsman',\n",
       " 'vexed began son abode short may',\n",
       " 'interested astonished cultivated',\n",
       " 'brought one invited produce']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "00fab83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "X = tfidf.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "121f0f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.41518962, ..., 0.41518962, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.5       , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.70710678, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f39bdf5",
   "metadata": {},
   "source": [
    "So now we can see that there are different values associated with a specific word. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9beda7c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
